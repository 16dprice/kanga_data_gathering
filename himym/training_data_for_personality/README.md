The training data here was an attempt at producing data that would extract only the "personality" out of a character's speech. The structure of the training data is the same structure recommended [here](https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset) in a few places. OpenAI gives some use cases where, when you fine-tine a model, you would have all empty prompts and completions for those prompts where the completions are just samples of text that something (or someone) might say. In this, the completions were all the lines of a particular character from HIMYM.

The difference between this data and any other data is that I replaced the common names (Robin, Ted, Barney, Marshal, and Lily) in the scripts with random names located in `random_names.txt` at the top level of this project. The idea was that the fine-tuned model would be less focused on learning that the speech from Robin's character talked about Ted a lot and more focused on the syntactical and grammatical structure of what Robin says. Of course, each character still talks about certain specific topics, but this was a hopeful step in the direction of getting a general "personality".